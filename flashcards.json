[
  {
    "question": "What are the stages involved in developing a language model?",
    "answer": "- Stage 1: Building<br>  - Data & Preparation<br>  - LLM Architecture<br>- Stage 2: Pretraining<br>  - Pre-train<br>  - Training Loop<br>- Stage 3: Fine-Tuning<br>  - Model Evaluation<br>  - Fine-tune"
  },
  {
    "question": "What is the main purpose of a language model?",
    "answer": "- To predict the next word given some context.<br>- Example: LLMs learn to predict one word at a time from a sequence of text."
  },
  {
    "question": "Why is data quality important for training language models?",
    "answer": "- Quality of data impacts the model's ability to learn and reason.<br>- Filtering data ensures the model learns useful knowledge and improves reasoning ability."
  },
  {
    "question": "What common architecture do most large language models (LLMs) use?",
    "answer": "- Transformer architecture.<br>- Based on a self-attention mechanism.<br>- Outperforms recurrent and convolutional models through parallelization and scalability."
  },
  {
    "question": "What are some issues with RNNs and LSTMs that Transformers overcome?",
    "answer": "- RNNs:<br>  - Inherently sequential, inhibiting parallelization.<br>  - Vanishing gradient problem with longer sequences.<br>- LSTMs:<br>  - Do not scale well.<br>  - Memory issues.<br>  - No explicit modeling of long-short range dependencies.<br>  - Sequential computation inhibiting parallelization."
  },
  {
    "question": "Describe the self-attention mechanism in Transformers.",
    "answer": "- Involves creating three matrices: Query (Q), Key (K), and Value (V).<br>- Weights for Q, K, and V are initially randomly assigned.<br>- Scores are normalized using the softmax activation function and scaled by the dimension.<br>- Example: For the phrase 'You are welcome', calculate the score for each word by the dot product of the Query vector with the keys vectors of all words."
  },
  {
    "question": "What is Multi-Head Self-Attention in Transformers?",
    "answer": "- Allows parallel functions to attend to different parts of the text.<br>- Performs attention multiple times (e.g., eight heads).<br>- Concatenates all attention heads and multiplies by a weight matrix \\( W_O \\)."
  },
  {
    "question": "What are the core and secondary parts of the Transformer Encoder?",
    "answer": "- Core Parts:<br>  - Multi-Headed Attention<br>  - Feed Forward layer<br>- Secondary Parts:<br>  - Residual connections<br>  - Layer normalization<br>- Positional Encoding: Accounts for the order of words in the input sequence."
  },
  {
    "question": "What is the process of pretraining a language model?",
    "answer": "- Data & Preparation<br>- LLM Architecture<br>- Pre-train<br>- Training Loop<br>- Uses large datasets and powerful hardware to train models.<br>- Think of it as compressing the internet."
  },
  {
    "question": "What is Instruction Tuning in language models?",
    "answer": "- Makes language models follow intent.<br>- Collects examples of instruction/output pairs across many tasks.<br>- Enhances the model's ability to follow human-like instructions."
  },
  {
    "question": "What are Zero-Shot and Few-Shot Learning in the context of prompting language models?",
    "answer": "- Zero-Shot Learning: Prompting the model without providing examples.<br>  - Example: Q: Where was Tom Brady born? A: Tokyo (based on the context provided).<br>- Few-Shot Learning: Providing a set of a few examples to demonstrate the task.<br>- Improves model's performance by showing task-specific examples."
  },
  {
    "question": "What is Natural Language Generation (NLG)?",
    "answer": "- Sub-field of Natural Language Processing (NLP)<br>- Comprises Natural Language Understanding (NLU) + NLG<br>- Focuses on producing fluent, coherent, and useful written or spoken text"
  },
  {
    "question": "List some example uses of NLG.",
    "answer": "- Machine Translation: Translates text from one language to another<br>- Dialogue Systems: Produces responses based on dialogue history and queries<br>- Text Summarization: Creates concise summaries from long documents<br>- Code Generation: Suggests new code or auto-completes based on surrounding code<br>- Data to Text: Converts table data into descriptive text<br>- Image Description: Generates textual descriptions from visual inputs"
  },
  {
    "question": "What are the categories of NLG tasks based on the spectrum of open-endedness?",
    "answer": "- Non-open-ended (Machine Translation): Limited diversity in output<br>- Moderately open-ended (Text Summarization, Task-driven Dialogue, Chit-Chat Dialogue): More diverse outputs<br>- Highly open-ended (Story Generation): Extremely diverse output space"
  },
  {
    "question": "Explain the task of text summarization.",
    "answer": "- Given input text \\(x\\), write a shorter summary \\(y\\) containing the main information of \\(x\\)<br>- Can be single-document or multi-document summarization<br>&nbsp;&nbsp;- Single-document: Abstract, outline, headline from one document<br>&nbsp;&nbsp;- Multiple-document: Gist of content from multiple documents"
  },
  {
    "question": "What are the main approaches to text summarization?",
    "answer": "- Extractive Summarization: Selects phrases or sentences from the source document(s)<br>- Abstractive Summarization: Generates new text using natural language generation techniques<br>- Hybrid Approaches: Combines extractive and abstractive methods"
  },
  {
    "question": "Describe the copying mechanism in seq2seq models for summarization.",
    "answer": "- Helps seq2seq systems copy words/phrases from the input to the output<br>- Useful for summarization by providing a hybrid extractive/abstractive approach<br>- Formula: \\( P_w = p_{gen}P_{vocab}(w) + (1 - p_{gen})\\sum_{i:w_i=w} a_{ti} \\)"
  },
  {
    "question": "What are the challenges associated with copying mechanisms in seq2seq models?",
    "answer": "- Excessive copying can turn an abstractive system into an extractive one<br>- Lack of an overall content selection strategy, particularly for long inputs"
  },
  {
    "question": "What advancements did the transition to the Transformers era bring for text summarization?",
    "answer": "- Reliance on self-attention mechanisms<br>- Allows more parallelization and better performance<br>- Models can consider entire sequences simultaneously, weighting the significance of each word"
  },
  {
    "question": "What is BERTSum and how does it work for extractive summarization?",
    "answer": "- Adapted BERT model for extractive summarization<br>- Uses custom embeddings to distinguish multiple sentences within a document<br>- Employs an encoder similar to BERT and a ranking mechanism to select top sentences for summary"
  },
  {
    "question": "Describe the PEGASUS model and its approach to abstractive summarization.",
    "answer": "- Pre-training with Extracted Gap-sentences for Abstractive Summarization<br>- Gap Sentence Generation (GSG): Removes whole sentences from documents and tasks the model with recovering them<br>- Generates concise, abstractive summaries by condensing information efficiently"
  },
  {
    "question": "What are the two main approaches to handling long documents in text summarization?",
    "answer": "- Hierarchical Processing: Breaks document into chunks, summarizes each chunk, then builds a summary of summaries<br>- Improved Attention: Window-based attention with fixed-sized windows surrounding each token, combining with global attention for better context"
  },
  {
    "question": "What is ethics and why is it important in AI?",
    "answer": "- Ethics is the study of what is good and bad, right and wrong.<br>- It aims to determine how one ought to live and what actions to take.<br>- In AI, ethics guides responsible use and addresses potential harm and fairness."
  },
  {
    "question": "What are some common ethical considerations in AI research and development?",
    "answer": "- Fairness: Ensuring no discrimination based on race, gender, age, etc.<br>- Transparency: Making development and use explainable.<br>- Accountability: Holding developers and users responsible.<br>- Privacy: Protecting individual data.<br>- Security: Preventing misuse through appropriate measures."
  },
  {
    "question": "Describe an example of bias in AI and its potential impact.",
    "answer": "- Example: Deep neural networks identifying sexual orientation from facial images with high accuracy.<br>- Impact: Risk to privacy and safety, potential discrimination in employment, healthcare, and legal prosecution in some countries."
  },
  {
    "question": "What are some methods to mitigate bias in AI models?",
    "answer": "- Removing signals that lead to problematic outputs.<br>- Adding signals that ensure desired variables are considered.<br>- Paying attention to the performance on subgroups with the worst outcomes."
  },
  {
    "question": "What is responsible AI and what principles does it encompass?",
    "answer": "- Responsible AI ensures ethical, fair, transparent, and accountable AI system development.<br>- Principles include:<br>  - Fairness<br>  - Transparency<br>  - Accountability<br>  - Privacy<br>  - Security"
  },
  {
    "question": "What are Datasheets for Datasets and Model Cards for Model Reporting?",
    "answer": "- <b>Datasheets for Datasets:</b> Standardized documentation format for datasets to increase transparency and accountability.<br>- <b>Model Cards for Model Reporting:</b> Documentation for machine learning models to make them easier to understand, evaluate, and compare."
  },
  {
    "question": "What are some biases that can affect data and model interpretation in AI?",
    "answer": "- Reporting Bias: Shared information doesn't reflect real-world frequencies.<br>- Selection Bias: Sample doesn't represent a random population.<br>- Out-group Homogeneity Bias: Seeing outgroup members as more alike.<br>- Confirmation Bias: Searching for information that confirms preexisting beliefs."
  },
  {
    "question": "What are some challenges and benefits of responsible AI?",
    "answer": "- Challenges:<br>  - Addressing biases.<br>  - Ensuring transparency.<br>  - Developing oversight mechanisms.<br>- Benefits:<br>  - Increased trust in AI systems.<br>  - Better decision-making.<br>  - More equitable outcomes."
  },
  {
    "question": "Why is it important to question the purpose and potential harm of building an NLP model?",
    "answer": "- To ensure the model does not reinforce biases or discrimination.<br>- To consider the ethical implications and potential societal impact.<br>- To remain mindful of the iterative nature of improving AI responsibly."
  },
  {
    "question": "What is Automation Bias and how can it affect AI use?",
    "answer": "- Automation Bias: The tendency to favor automated suggestions over contradictory information.<br>- It can lead to over-reliance on AI outputs, ignoring potentially correct human judgments."
  },
  {
    "question": "How can researchers and developers ensure responsible AI use?",
    "answer": "- Acknowledge and document AI model use (Transparency).<br>- Ensure correctness, truthfulness, fairness, and appropriateness (Integrity).<br>- Adhere to integrity, be open to feedback, and disclose model limitations (Accountability)."
  }
]